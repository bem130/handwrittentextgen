{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff01873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.25.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4024e45-6aa1-4faf-aa8e-0459000ad5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 1 1-input.pdf --\n",
      "train: 23\n",
      "val  : 0\n",
      "-- 1 1-target.pdf --\n",
      "train: 23\n",
      "val  : 0\n",
      "-- 2 2-input.pdf --\n",
      "train: 23\n",
      "val  : 0\n",
      "-- 2 2-target.pdf --\n",
      "train: 22\n",
      "val  : 1\n",
      "-- 3 3-input.pdf --\n",
      "train: 22\n",
      "val  : 1\n",
      "-- 3 3-target.pdf --\n",
      "train: 21\n",
      "val  : 2\n",
      "-- 4 4-input.pdf --\n",
      "train: 22\n",
      "val  : 1\n",
      "-- 4 4-target.pdf --\n",
      "train: 23\n",
      "val  : 0\n",
      "-- 5 5-input.pdf --\n",
      "train: 21\n",
      "val  : 2\n",
      "-- 5 5-target.pdf --\n",
      "train: 23\n",
      "val  : 0\n",
      "-- 6 6-input.pdf --\n",
      "train: 21\n",
      "val  : 2\n",
      "-- 6 6-target.pdf --\n",
      "train: 22\n",
      "val  : 1\n",
      "-- 7 7-input.pdf --\n",
      "train: 23\n",
      "val  : 0\n",
      "-- 7 7-target.pdf --\n",
      "train: 19\n",
      "val  : 4\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageEnhance\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "dataset_dir = \"font_data\"\n",
    "input_dir = \"image\"\n",
    "\n",
    "def delete_folder_contents(folder_path):\n",
    "    # フォルダ内の全てのファイルとサブフォルダを削除\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)  # サブフォルダの場合は再帰的に削除\n",
    "        else:\n",
    "            os.remove(file_path)  # ファイルの場合は削除\n",
    "\n",
    "os.makedirs(os.path.join(dataset_dir,\"train/input\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_dir,\"train/target\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_dir,\"val/input\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_dir,\"val/target\"), exist_ok=True)\n",
    "\n",
    "delete_folder_contents(os.path.join(dataset_dir,\"train/input\"))\n",
    "delete_folder_contents(os.path.join(dataset_dir,\"train/target\"))\n",
    "delete_folder_contents(os.path.join(dataset_dir,\"val/input\"))\n",
    "delete_folder_contents(os.path.join(dataset_dir,\"val/target\"))\n",
    "\n",
    "\n",
    "# 画像切り出しの調整\n",
    "height = 128\n",
    "width = 512\n",
    "x = 0\n",
    "y = 30\n",
    "lineh = 150\n",
    "slidex = 100\n",
    "linemax = 23\n",
    "# 画像のコントラストを調整\n",
    "contrast = 2\n",
    "\n",
    "def generate_random_array(l, p):\n",
    "    return [\"val\" if random.random() < p else \"train\" for _ in range(l)]\n",
    "\n",
    "def proc(dataid,output_dir,input):\n",
    "    print(f\"-- {dataid} {input} --\")\n",
    "    # 各行をtrainとvalに分ける\n",
    "    datatype = generate_random_array(linemax,5/ 100)\n",
    "    # print(datatype)\n",
    "    print(f\"train: \"+str(datatype.count(\"train\")))\n",
    "    print(f\"val  : \"+str(datatype.count(\"val\")))\n",
    "    # PDFファイルを開く\n",
    "    doc = fitz.open(os.path.join(dataset_dir,input_dir,input))\n",
    "    for i, page in enumerate(doc):\n",
    "        images = page.get_images(full=True)\n",
    "        for img_index, img in enumerate(images):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            filepath = os.path.join(dataset_dir,input_dir,f\"{input_dir}.{image_ext}\")\n",
    "            with open(filepath, \"wb\") as img_file:\n",
    "                img_file.write(image_bytes)\n",
    "\n",
    "            # 画像を読み込む\n",
    "            input_image = Image.open(filepath)\n",
    "            # コントラストを調整する\n",
    "            enhancer = ImageEnhance.Contrast(input_image)\n",
    "            input_image = enhancer.enhance(contrast)\n",
    "\n",
    "            # 切り出す領域を指定（左、上、右、下）\n",
    "            inwidth, inheight = input_image.size\n",
    "            for linen in range(linemax):\n",
    "                sliden = 0\n",
    "                while x+slidex*sliden+width < inwidth:\n",
    "                    box = (x+slidex*sliden,y+lineh*linen,x+slidex*sliden+width,y+height+lineh*linen)\n",
    "                    cropped_image = input_image.crop(box)\n",
    "                    cropped_image.save(os.path.join(dataset_dir+\"/\"+datatype[linen]+\"/\"+output_dir,f\"{dataid}-{linen}-{sliden}.png\"))\n",
    "                    sliden+=1\n",
    "\n",
    "\n",
    "\n",
    "idlist = [1,2,3,4,5,6,7]\n",
    "\n",
    "for i in idlist:\n",
    "    proc(i,\"input/\",f\"{i}-input.pdf\")\n",
    "    proc(i,\"target/\",f\"{i}-target.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35529af4-7be4-4319-a322-0b4af9439b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000], Val Loss_G: 12.116859849294027, Val Loss_D: 0.8015609492858251, estimate: 2067 days, 18:45:00\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習する\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "project_dir = \"./\"\n",
    "\n",
    "train_input_dir = project_dir+'font_data/train/input/'\n",
    "train_target_dir = project_dir+'font_data/train/target/'\n",
    "\n",
    "val_input_dir = project_dir+'font_data/val/input/'\n",
    "val_target_dir = project_dir+'font_data/val/target/'\n",
    "\n",
    "epoch_dir = project_dir+'output/log/epoch/'\n",
    "model_dir = project_dir+'output/'\n",
    "prog_dir = project_dir+'output/prog/'\n",
    "\n",
    "os.makedirs(os.path.join(epoch_dir), exist_ok=True)\n",
    "os.makedirs(os.path.join(model_dir), exist_ok=True)\n",
    "os.makedirs(os.path.join(prog_dir), exist_ok=True)\n",
    "\n",
    "# Generator (U-Net)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        # Middle\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.encoder(x)\n",
    "        x2 = self.middle(x1)\n",
    "        return self.decoder(x2)\n",
    "\n",
    "\n",
    "# Discriminator (PatchGAN)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(2, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# Custom Dataset for loading images\n",
    "class FontDataset(Dataset):\n",
    "    def __init__(self, input_dir, target_dir, transform=None):\n",
    "        self.input_dir = input_dir\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.input_images = sorted(os.listdir(input_dir))\n",
    "        self.target_images = sorted(os.listdir(target_dir))\n",
    "        assert len(self.input_images) == len(self.target_images), \"入力画像とターゲット画像の数が一致していません\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_image = os.path.join(self.input_dir, self.input_images[idx])\n",
    "        target_image = os.path.join(self.target_dir, self.target_images[idx])\n",
    "\n",
    "        # 画像をPIL Imageとして開く\n",
    "        input_image = Image.open(input_image)\n",
    "        target_image = Image.open(target_image)\n",
    "\n",
    "        if self.transform:\n",
    "            input_image = self.transform(input_image)\n",
    "            target_image = self.transform(target_image)\n",
    "\n",
    "        return input_image, target_image\n",
    "\n",
    "def tensorDataset(input_dir, target_dir, transform, device):\n",
    "    \"\"\"Datasetを全部読み込む\"\"\"\n",
    "    input_images = sorted(os.listdir(input_dir))\n",
    "    target_images = sorted(os.listdir(target_dir))\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for i, t in zip(input_images, target_images):\n",
    "        i, t = os.path.join(input_dir, i), os.path.join(target_dir, t)\n",
    "        i, t = Image.open(i), Image.open(t)\n",
    "        if transform:\n",
    "            i, t = transform(i), transform(t)\n",
    "        i, t = i.to(device), t.to(device)\n",
    "        x.append(i)\n",
    "        y.append(t)\n",
    "    x, y = torch.stack(x), torch.stack(y)\n",
    "    return torch.utils.data.TensorDataset(x, y)\n",
    "\n",
    "def show_image(tensor_image, max_images=16):\n",
    "    \"\"\"\n",
    "    tensor_image : バッチサイズを持つ Tensor (B, C, H, W)\n",
    "    max_images   : 表示する画像の最大数\n",
    "    \"\"\"\n",
    "    # サブセットを選択\n",
    "    if tensor_image.size(0) > max_images:\n",
    "        tensor_image = tensor_image[:max_images]  # 最初の max_images 枚を取得\n",
    "    # Tensor を CPU に移動し、[0, 1] の範囲に正規化\n",
    "    tensor_image = tensor_image.detach().cpu()\n",
    "    tensor_image = (tensor_image + 1) / 2  # Normalize to [0, 1]\n",
    "    # グリッド画像を作成\n",
    "    grid = torchvision.utils.make_grid(tensor_image, nrow=4, padding=2, normalize=True)\n",
    "    # 画像を表示\n",
    "    plt.imshow(grid.permute(1, 2, 0).numpy())\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return plt\n",
    "\n",
    "# Validation loop\n",
    "def calculate_val_loss(generator, discriminator, val_loader, criterion_GAN, criterion_L1, device):\n",
    "    generator.eval()  # モデルを評価モードに切り替え\n",
    "    discriminator.eval()  # モデルを評価モードに切り替え\n",
    "\n",
    "    val_loss_G = 0\n",
    "    val_loss_D = 0\n",
    "    val_steps = len(val_loader)\n",
    "    gen_output = 0\n",
    "\n",
    "    with torch.no_grad():  # 勾配計算を行わない\n",
    "        for input_image, target_image in val_loader:\n",
    "            input_image, target_image = input_image.to(device), target_image.to(device)\n",
    "\n",
    "            # Generatorの出力を取得\n",
    "            gen_output = generator(input_image)\n",
    "\n",
    "            # Discriminatorの損失\n",
    "            pred_real = discriminator(torch.cat((input_image, target_image), 1))\n",
    "            loss_D_real = criterion_GAN(pred_real, torch.ones_like(pred_real))\n",
    "\n",
    "            pred_fake = discriminator(torch.cat((input_image, gen_output), 1))\n",
    "            loss_D_fake = criterion_GAN(pred_fake, torch.zeros_like(pred_fake))\n",
    "            loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "\n",
    "            # Generatorの損失\n",
    "            loss_GAN = criterion_GAN(pred_fake, torch.ones_like(pred_fake))\n",
    "            loss_L1 = criterion_L1(gen_output, target_image) * 100\n",
    "            loss_G = loss_GAN + loss_L1\n",
    "\n",
    "            val_loss_G += loss_G.item()\n",
    "            val_loss_D += loss_D.item()\n",
    "\n",
    "    return val_loss_G / val_steps, val_loss_D / val_steps, gen_output\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    batch_size = 2  #32\n",
    "    num_epochs = 10000\n",
    "    os.makedirs(os.path.join(epoch_dir), exist_ok=True)\n",
    "\n",
    "    # Transforms\n",
    "    transform = transforms.Compose([transforms.Resize((128, 512)), transforms.Grayscale(), transforms.ToTensor()])\n",
    "\n",
    "    # DataLoader setup (訓練データと検証データ)\n",
    "    #train_dataset = FontDataset(train_input_dir, train_target_dir, transform)\n",
    "    train_dataset = tensorDataset(train_input_dir, train_target_dir, transform, device)  # データをcuda上に\n",
    "    #val_dataset = FontDataset(val_input_dir, val_target_dir, transform)  # 同じディレクトリで分割する場合\n",
    "    val_dataset = tensorDataset(val_input_dir, val_target_dir, transform, device)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)  # 既にcudaにあるので0\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    generator = Generator().to(device)\n",
    "    discriminator = Discriminator().to(device)\n",
    "\n",
    "    criterion_GAN = nn.BCEWithLogitsLoss().to(device)\n",
    "    criterion_L1 = nn.L1Loss().to(device)\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "    # Loss tracking lists\n",
    "    loss_G_list = []\n",
    "    loss_D_list = []\n",
    "    val_loss_G_list = []\n",
    "    val_loss_D_list = []\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        generator.train()  # モデルを学習モードに切り替え\n",
    "        discriminator.train()  # モデルを学習モードに切り替え\n",
    "\n",
    "        for i, (input_image, target_image) in enumerate(train_loader):\n",
    "            input_image, target_image = input_image.to(device), target_image.to(device)\n",
    "\n",
    "            # Generator training\n",
    "            optimizer_G.zero_grad()\n",
    "            gen_output = generator(input_image)\n",
    "\n",
    "            # Discriminator loss\n",
    "            pred_fake = discriminator(torch.cat((input_image, gen_output), 1))\n",
    "            loss_GAN = criterion_GAN(pred_fake, torch.ones_like(pred_fake))\n",
    "            loss_L1 = criterion_L1(gen_output, target_image) * 100\n",
    "            loss_G = loss_GAN + loss_L1\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # Discriminator training\n",
    "            optimizer_D.zero_grad()\n",
    "            pred_real = discriminator(torch.cat((input_image, target_image), 1))\n",
    "            loss_D_real = criterion_GAN(pred_real, torch.ones_like(pred_real))\n",
    "            pred_fake = discriminator(torch.cat((input_image, gen_output.detach()), 1))\n",
    "            loss_D_fake = criterion_GAN(pred_fake, torch.zeros_like(pred_fake))\n",
    "            loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # Print logs every 100 steps\n",
    "            if i % 100 == 0:\n",
    "                # print(f\"Epoch [{epoch}/{num_epochs}], Step [{i}/{len(train_loader)}], Loss_G: {loss_G.item()}, Loss_D: {loss_D.item()}\")\n",
    "                loss_G_list.append(loss_G.item())\n",
    "                loss_D_list.append(loss_D.item())\n",
    "\n",
    "        # Validate and print validation loss\n",
    "        val_loss_G, val_loss_D, val_output = calculate_val_loss(generator, discriminator, val_loader, criterion_GAN, criterion_L1, device)\n",
    "        # print(f\"Epoch [{epoch}/{num_epochs}], Val Loss_G: {val_loss_G}, Val Loss_D: {val_loss_D}\")\n",
    "        val_loss_G_list.append(val_loss_G)\n",
    "        val_loss_D_list.append(val_loss_D)\n",
    "\n",
    "        # Save generated image every 10 epochs\n",
    "        if (epoch) % 5 == 0:\n",
    "            elapsed = datetime.datetime.now() - start_time\n",
    "            remain = elapsed / (epoch+0.001) * num_epochs\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}], Val Loss_G: {val_loss_G}, Val Loss_D: {val_loss_D}, estimate: {remain}\")\n",
    "        if (epoch) % 20 == 0:\n",
    "            show_image(gen_output).savefig(prog_dir+'gen_output.png', bbox_inches='tight', pad_inches=0)\n",
    "            show_image(val_output).savefig(prog_dir+'val_output.png', bbox_inches='tight', pad_inches=0)\n",
    "            # Plotting the loss curves\n",
    "            plt.figure(figsize=(6, 3))\n",
    "            plt.plot(loss_G_list, label='t G Loss')\n",
    "            plt.plot(loss_D_list, label='t D Loss')\n",
    "            plt.plot(val_loss_G_list, label='v G Loss', linestyle='dashed')\n",
    "            plt.plot(val_loss_D_list, label='v D Loss', linestyle='dashed')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.title('Generator and Discriminator Losses')\n",
    "            plt.savefig(prog_dir+'loss_plot.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        # Save model every 100 epochs\n",
    "        if (epoch) % 100 == 0:\n",
    "            torch.save(generator.state_dict(), model_dir+'/generator.'+str(epoch)+'.pth')\n",
    "\n",
    "    # Final model save\n",
    "    torch.save(generator.state_dict(), model_dir+'/generator.pth')\n",
    "    torch.save(discriminator.state_dict(), model_dir+'/discriminator.pth')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37df6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generator (U-Net) と訓練済みモデルをインポート\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        # Middle\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.encoder(x)\n",
    "        x2 = self.middle(x1)\n",
    "        return self.decoder(x2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.encoder(x)\n",
    "        x2 = self.middle(x1)\n",
    "        return self.decoder(x2)\n",
    "\n",
    "\n",
    "def generate_image(input_image, model_path, output_image_path):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    generator = Generator().to(device)\n",
    "    generator.load_state_dict(torch.load(model_path,map_location=torch.device('cpu')))\n",
    "    generator.eval()\n",
    "    transform = transforms.Compose([transforms.Resize((128,512)), transforms.ToTensor()])\n",
    "    input_image = transform(input_image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_image = generator(input_image)\n",
    "    return generated_image\n",
    "\n",
    "def show_image(tensor_image):\n",
    "    tensor_image = tensor_image.detach().cpu()\n",
    "    tensor_image = (tensor_image + 1) / 2\n",
    "    grid = torchvision.utils.make_grid(tensor_image, nrow=4, padding=2, normalize=True)\n",
    "    plt.imshow(grid.permute(1, 2, 0).numpy())\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "WHITE = (255,255,255)\n",
    "BLACK = (0,0,0)\n",
    "def generateInput(text,size,font):\n",
    "    font_path = \"./font_data/font/\"+font\n",
    "    fontPIL = ImageFont.truetype(font_path, size)\n",
    "    x = 0\n",
    "    y = -20\n",
    "    img = Image.new(\"RGB\", (512, 128), WHITE)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.text(xy=(x,y), text=text, fill=BLACK, font=fontPIL)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使う\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Paths to the input image, model, and output image\n",
    "    input_image = generateInput(\"手書き文字\",100,\"notosansjp/NotoSansJP-Bold.ttf\")\n",
    "    # input_image.show()\n",
    "    model_path = \"output/generator.200.pth\"  # 訓練済みモデルのパス\n",
    "    output_image_path = \"output/generated_image.png\"  # 生成された画像の保存先\n",
    "\n",
    "    # 画像を生成して表示\n",
    "    output_image = generate_image(input_image, model_path, output_image_path)\n",
    "    # plt.imshow(input_image)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    show_image(output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5acfed4-9d19-45b1-8b7a-48d0f4fd52e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
